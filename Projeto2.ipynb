{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Ellen Beatriz Shen\n",
    "\n",
    "Nome: Gabriela Moreno Boriero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Gabi_XPS\\AppData\\Local\\pip\\Cache\\wheels\\2a\\a9\\0a\\4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-0.5.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import re \n",
    "import emoji\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leitura do excel para treinar o c√≥digo\n",
    "tudo = pd.read_excel(\"base_acai.xlsx\", sheet_name=\"Treinamento\")\n",
    "\n",
    "#S√©rie de todos os dados + sua tabela absoluta\n",
    "serie_tudo = pd.Series(tudo.Treinamento)\n",
    "tabela_tudo_absoluta = serie_tudo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fun√ß√£o para limpar os sinais b√°sicos.\n",
    "def limpeza(texto):\n",
    "    import string\n",
    "    pontuacao = '[!-.:?;]'\n",
    "    padrao = re.compile(pontuacao)\n",
    "    text_subbed = re.sub(padrao, ' ', texto)\n",
    "    letras=[]\n",
    "    for letra in text_subbed:  \n",
    "        letras.append(letra)\n",
    "    i=1\n",
    "    espa√ßo=\" \"\n",
    "    frase_separando_emoji=\"\"\n",
    "    while i<= (len(letras)-1):        \n",
    "        if letras[i-1]==letras[i]:\n",
    "            if letras[i] in UNICODE_EMOJI:\n",
    "                frase_separando_emoji+=letras[i-1]\n",
    "                frase_separando_emoji+=(espa√ßo)\n",
    "                frase_separando_emoji+=(letras[i])\n",
    "                letras.remove(letras[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            frase_separando_emoji+=(letras[i-1])\n",
    "            i+=1\n",
    "    return frase_separando_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "um a√ßa√≠ agr ü•∞ ü•∞\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'um a√ßa√≠ agr ü•∞ ü•∞'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letras=[]\n",
    "for letra in frase_limpa:  \n",
    "    letras.append(letra)\n",
    "i=1\n",
    "espa√ßo=\" \"\n",
    "frase_separando_emoji=\"\"\n",
    "while i<= (len(letras)-1):        \n",
    "    if letras[i-1]==letras[i]:\n",
    "        if letras[i] in UNICODE_EMOJI:\n",
    "            frase_separando_emoji+=letras[i-1]\n",
    "            frase_separando_emoji+=(espa√ßo)\n",
    "            frase_separando_emoji+=(letras[i])\n",
    "            letras.remove(letras[i])\n",
    "        i+=1\n",
    "    else:\n",
    "        frase_separando_emoji+=(letras[i-1])\n",
    "        i+=1\n",
    "frase_separando_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "relevante_acai = limpeza((open(\"relevante.txt\", \"r\", encoding=\"utf8\").read()).lower())\n",
    "irrelevante_acai = limpeza((open(\"irrelevante.txt\", \"r\", encoding=\"utf8\").read()).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante_relativa = (pd.Series(relevante_acai.split())).value_counts(True)\n",
    "relevante_absoluta = (pd.Series(relevante_acai.split())).value_counts(False)\n",
    "\n",
    "irrelevante_relativa = (pd.Series(irrelevante_acai.split())).value_counts(True)\n",
    "irrelevante_absoluta = (pd.Series(irrelevante_acai.split())).value_counts(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidade_relevante = relevante_absoluta.sum()/tabela_tudo_absoluta.sum()\n",
    "probabilidade_irrelevante = irrelevante_absoluta.sum()/tabela_tudo_absoluta.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace(palavra, tabela1, tabela2):\n",
    "    if palavra in tabela1:\n",
    "        x = tabela1[palavra]\n",
    "    else:\n",
    "        x = 0\n",
    "        \n",
    "    if palavra in tabela2:\n",
    "        y = tabela2[palavra]\n",
    "    else:\n",
    "        y = 0 \n",
    "    \n",
    "    prob_relevante = (x + 1)/ (len(tabela1) + len(set(tabela1+tabela2)))\n",
    "    prob_irrelevante = (y + 1)/ (len(tabela2) + len(set(tabela1+tabela2)))\n",
    "    return [prob_relevante, prob_irrelevante]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_teste = pd.read_excel(\"base_acai.xlsx\",sheet_name=\"Teste\")\n",
    "series_tweets = pd.Series(list(base_teste.Teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_limpos = []\n",
    "for tweet in series_tweets:\n",
    "    tweets_limpos.append(limpeza(tweet.lower()))\n",
    "\n",
    "    \n",
    "classificacao = {}\n",
    "lista_classificador=[]\n",
    "for frase in tweets_limpos:\n",
    "    palavras_da_frase = list(frase.split())\n",
    "    relevante = 1\n",
    "    irrelevante = 1\n",
    "    \n",
    "    for palavra in palavras_da_frase:\n",
    "\n",
    "        if palavra in relevante_relativa and \\\n",
    "        palavra in irrelevante_relativa:\n",
    "            relevante *= relevante_relativa[palavra]\n",
    "            irrelevante *= irrelevante_relativa[palavra]\n",
    "            \n",
    "        elif palavra in relevante_relativa and \\\n",
    "        palavra not in irrelevante_relativa:\n",
    "            relevante *= relevante_relativa[palavra]\n",
    "            irrelevante *= laplace(palavra,relevante_relativa,irrelevante_relativa)[1]\n",
    "        \n",
    "        elif palavra in irrelevante_relativa and \\\n",
    "        palavra not in relevante_relativa:\n",
    "            relevante *= laplace(palavra,relevante_relativa,irrelevante_relativa)[0]\n",
    "            irrelevante *= irrelevante_relativa[palavra]\n",
    "            \n",
    "        else:\n",
    "            relevante *= laplace(palavra,relevante_relativa,irrelevante_relativa)[0]\n",
    "            irrelevante *= laplace(palavra,relevante_relativa,irrelevante_relativa)[1]\n",
    "            \n",
    "    prob_relevante = probabilidade_relevante*relevante\n",
    "    prob_irrelevante = probabilidade_irrelevante*irrelevante\n",
    "    \n",
    "    if prob_relevante > prob_irrelevante:\n",
    "        classificacao[frase] = 0\n",
    "        lista_classificador.append(0)\n",
    "    else:\n",
    "        classificacao[frase] = 1\n",
    "        lista_classificador.append(1)\n",
    "       \n",
    "classificados = pd.Series(classificacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#comparando o teste com a classifica√ß√£o \n",
    "for tweet in classificacao:\n",
    "    dic={\n",
    "        'Tweet': tweets_limpos,\n",
    "        'Resultafo Teste': lista_classificador,\n",
    "        'Classifica√ß√£o': base_teste[\"Classe\"]\n",
    "    }\n",
    "tabela_classifia√ß√£o= pd.DataFrame(dic, columns=['Tweet','Resultafo Teste','Classifica√ß√£o'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparando o teste com a classifica√ß√£o \n",
    "for tweet in classificacao:\n",
    "    dic={\n",
    "        'Tweet': tweets_limpos,\n",
    "        'Resultafo Teste': lista_classificador,\n",
    "        'Classifica√ß√£o': base_teste[\"Classe\"]\n",
    "    }\n",
    "tabela_classifia√ß√£o= pd.DataFrame(dic, columns=['Tweet','Resultafo Teste','Classifica√ß√£o'])\n",
    "tabela_classifia√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "certos=0\n",
    "errados=0\n",
    "\n",
    "for teste,certo in zip(lista_classificador,base_teste[\"Classe\"]):\n",
    "    if teste==certo:\n",
    "        certos+=1\n",
    "    else:\n",
    "        errados+=1\n",
    "       \n",
    "porcentagem_certos=(certos/299)*100\n",
    "porcentagem_errados=(errados/299)*100\n",
    "print(\"Porcentagem de acertos= {}%\".format(porcentagem_certos))\n",
    "print(\"Porcentagem de erros= {}%\".format(porcentagem_errados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verdadeiros_positivo=0\n",
    "falsos_positivos=0\n",
    "verdadeiros_negativos=0\n",
    "falsos_negativos=0\n",
    "#relevante=0 e irrelevante=1\n",
    "for resultado_teste,resultado_certo in zip(lista_classificador,base_teste[\"Classe\"]):\n",
    "    if resultado_certo==0 and resultado_teste==0:\n",
    "        verdadeiros_positivo+=1\n",
    "    elif resultado_certo==1 and resultado_teste==0:\n",
    "        falsos_positivos+=1\n",
    "    elif resultado_certo==1 and resultado_teste==1:\n",
    "        verdadeiros_negativos+=1\n",
    "    elif falsos_negativos==0 and resultado_teste==1:\n",
    "        falsos_negativos+=1\n",
    "    \n",
    "Porcentagem_verdadeiros_positivo=(verdadeiros_positivo/229)*100\n",
    "Porcentagem_falsos_positivos=(falsos_positivos/229)*100\n",
    "Porcentagem_verdadeiros_negativos=(verdadeiros_negativos/229)*100\n",
    "Porcentagem_falsos_negativos=(falsos_negativos/229)*100\n",
    "\n",
    "print(\"Porcentagem de verdadeiros positivos: {}%\".format(Porcentagem_verdadeiros_positivo))\n",
    "print(\"Porcentagem de falsos positivos: {}%\".format(Porcentagem_falsos_positivos))\n",
    "print(\"Porcentagem de verdadeiros negativos: {}%\".format(Porcentagem_verdadeiros_negativos))\n",
    "print(\"Porcentagem de falsos negativos: {}%\".format(Porcentagem_falsos_negativos))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verdadeiros_positivo=0\n",
    "falsos_positivos=0\n",
    "verdadeiros_negativos=0\n",
    "falsos_negativos=0\n",
    "for teste, certo in zip(classificado, base_teste[\"Classe\"]):\n",
    "    if  certo!=1 and teste!=1:\n",
    "        verdadeiros_positivo+=1\n",
    "    elif certo==1 and teste!=1:\n",
    "        falsos_positivos+=1\n",
    "    elif certo==1 and teste==1:\n",
    "        verdadeiros_negativos+=1\n",
    "    elif certo!=1 and teste==1:\n",
    "        falsos_negativos+=1\n",
    "        \n",
    "Porcentagem_verdadeiros_positivos= (verdadeiros_positivo/449)*100\n",
    "Porcentagem_falsos_positivos= (falsos_positivos/449)*100\n",
    "Porcentagem_verdadeiros_negativos= (verdadeiros_negativos/449)*100\n",
    "Porcentagem_falsos_negativos= (falsos_negativos/449)*100\n",
    "\n",
    "print(\"Porcentagem de verdadeiros positivos: {}%\".format(Porcentagem_verdadeiros_positivos))\n",
    "print(\"Porcentagem de falsos positivos: {}%\".format(Porcentagem_falsos_positivos))\n",
    "print(\"Porcentagem de verdadeiros negativo: {}%\".format(Porcentagem_verdadeiros_negativos))\n",
    "print(\"Porcentagem de falsos negativos: {}%\".format(Porcentagem_falsos_negativos))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
