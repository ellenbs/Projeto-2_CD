{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Ellen Beatriz Shen\n",
    "\n",
    "Nome: Gabriela Moreno Boriero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import re \n",
    "import emoji\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leitura do excel para treinar o código\n",
    "tudo = pd.read_excel(\"base_acai.xlsx\", sheet_name=\"Treinamento\")\n",
    "\n",
    "#Série de todos os dados + sua tabela absoluta\n",
    "serie_tudo = pd.Series(tudo.Treinamento)\n",
    "tabela_tudo_absoluta = serie_tudo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para limpar os sinais básicos.\n",
    "def limpeza(texto):\n",
    "    import string\n",
    "    pontuacao = '[!-.:?;]'\n",
    "    padrao = re.compile(pontuacao)\n",
    "    text_subbed = re.sub(padrao, ' ', texto)\n",
    "    letras=[]\n",
    "    for letra in text_subbed:  \n",
    "        letras.append(letra)\n",
    "    i=1\n",
    "    espaço=\" \"\n",
    "    frase_separando_emoji=\"\"\n",
    "    while i<= (len(letras)-1):        \n",
    "        if letras[i-1]==letras[i]:\n",
    "            if letras[i] in UNICODE_EMOJI:\n",
    "                frase_separando_emoji+=letras[i-1]\n",
    "                frase_separando_emoji+=(espaço)\n",
    "                frase_separando_emoji+=(letras[i])\n",
    "                letras.remove(letras[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            frase_separando_emoji+=(letras[i-1])\n",
    "            i+=1\n",
    "    return frase_separando_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "relevante_acai = limpeza((open(\"relevante.txt\", \"r\", encoding=\"utf8\").read()).lower())\n",
    "irrelevante_acai = limpeza((open(\"irrelevante.txt\", \"r\", encoding=\"utf8\").read()).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante_relativa = (pd.Series(relevante_acai.split())).value_counts(True)\n",
    "relevante_absoluta = (pd.Series(relevante_acai.split())).value_counts(False)\n",
    "\n",
    "irrelevante_relativa = (pd.Series(irrelevante_acai.split())).value_counts(True)\n",
    "irrelevante_absoluta = (pd.Series(irrelevante_acai.split())).value_counts(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidade_relevante = relevante_absoluta.sum()/tabela_tudo_absoluta.sum()\n",
    "probabilidade_irrelevante = irrelevante_absoluta.sum()/tabela_tudo_absoluta.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sem laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_teste = pd.read_excel(\"base_acai.xlsx\",sheet_name=\"Teste\")\n",
    "series_tweets = pd.Series(list(base_teste.Teste))\n",
    "\n",
    "tweets_limpos = []\n",
    "for tweet in series_tweets:\n",
    "    tweets_limpos.append(limpeza(tweet.lower()))\n",
    "\n",
    "    \n",
    "classificacao = {}\n",
    "classificado=[]\n",
    "for frase in tweets_limpos:\n",
    "    palavras = list(frase.split())\n",
    "    for palavra in palavras:\n",
    "        relevante = 1\n",
    "        n_relevante = 1\n",
    "        if palavra in relevante_relativa:\n",
    "            relevante *= relevante_relativa[palavra]\n",
    "        if palavra in irrelevante_relativa:\n",
    "            n_relevante *= irrelevante_relativa[palavra]\n",
    "        else:\n",
    "            relevante*1\n",
    "            n_relevante*1\n",
    "    prob_relevante = probabilidade_relevante*relevante\n",
    "    prob_n_relevante = probabilidade_irrelevante*n_relevante\n",
    "    if prob_relevante > prob_n_relevante:\n",
    "        classificacao[frase] = 0\n",
    "        classificado.append(0)\n",
    "    else:\n",
    "        classificacao[frase] = 1\n",
    "        classificado.append(1)\n",
    "\n",
    "        \n",
    "teste_classificado = pd.Series(classificacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparando o teste com a classificação\n",
    "for tweet in classificacao:\n",
    "    data = {\n",
    "    'Frase': tweets_limpos  ,\n",
    "    'Resultado Teste': classificado,\n",
    "    'Classificação': base_teste[\"Classe\"]\n",
    "    }\n",
    "tabela_classificacao = pd.DataFrame(data, columns=['Frase', 'Resultado Teste','Classificação'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de acertos= 63.75545851528385%\n",
      "Porcentagem de erros= 67.24890829694323%\n"
     ]
    }
   ],
   "source": [
    "certos=0\n",
    "erros=0\n",
    "for teste, certo in zip(classificado, base_teste[\"Classe\"]):\n",
    "    if teste==certo:\n",
    "        certos+=1\n",
    "    else:\n",
    "        erros+=1\n",
    "\n",
    "porcentagem_certos=(certos/229)*100\n",
    "porcentagem_erros=(erros/229)*100\n",
    "print(\"Porcentagem de acertos= {}%\".format(porcentagem_certos))\n",
    "print(\"Porcentagem de erros= {}%\".format(porcentagem_erros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de verdadeiros positivos: 56.33187772925764%\n",
      "Porcentagem de falsos positivos: 58.951965065502186%\n",
      "Porcentagem de verdadeiros negativos: 7.423580786026202%\n",
      "Porcentagem de falsos negativos: 0.43668122270742354%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_positivo=0\n",
    "falsos_positivos=0\n",
    "verdadeiros_negativos=0\n",
    "falsos_negativos=0\n",
    "#relevante=0 e irrelevante=1\n",
    "for resultado_teste,resultado_certo in zip(classificado,base_teste[\"Classe\"]):\n",
    "    if resultado_certo==0 and resultado_teste==0:\n",
    "        verdadeiros_positivo+=1\n",
    "    elif resultado_certo==1 and resultado_teste==0:\n",
    "        falsos_positivos+=1\n",
    "    elif resultado_certo==1 and resultado_teste==1:\n",
    "        verdadeiros_negativos+=1\n",
    "    elif falsos_negativos==0 and resultado_teste==1:\n",
    "        falsos_negativos+=1\n",
    "    \n",
    "Porcentagem_verdadeiros_positivo=(verdadeiros_positivo/229)*100\n",
    "Porcentagem_falsos_positivos=(falsos_positivos/229)*100\n",
    "Porcentagem_verdadeiros_negativos=(verdadeiros_negativos/229)*100\n",
    "Porcentagem_falsos_negativos=(falsos_negativos/229)*100\n",
    "\n",
    "print(\"Porcentagem de verdadeiros positivos: {}%\".format(Porcentagem_verdadeiros_positivo))\n",
    "print(\"Porcentagem de falsos positivos: {}%\".format(Porcentagem_falsos_positivos))\n",
    "print(\"Porcentagem de verdadeiros negativos: {}%\".format(Porcentagem_verdadeiros_negativos))\n",
    "print(\"Porcentagem de falsos negativos: {}%\".format(Porcentagem_falsos_negativos))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace(palavra, tabela1, tabela2):\n",
    "    if palavra in tabela1:\n",
    "        x = tabela1[palavra]\n",
    "    else:\n",
    "        x = 0\n",
    "        \n",
    "    if palavra in tabela2:\n",
    "        y = tabela2[palavra]\n",
    "    else:\n",
    "        y = 0 \n",
    "    \n",
    "    prob_relevante = (x + 1)/ (len(tabela1) + len(set(tabela1+tabela2)))\n",
    "    prob_irrelevante = (y + 1)/ (len(tabela2) + len(set(tabela1+tabela2)))\n",
    "    return [prob_relevante, prob_irrelevante]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_teste = pd.read_excel(\"base_acai.xlsx\",sheet_name=\"Teste\")\n",
    "series_tweets = pd.Series(list(base_teste.Teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_limpos = []\n",
    "for tweet in series_tweets:\n",
    "    tweets_limpos.append(limpeza(tweet.lower()))\n",
    "\n",
    "    \n",
    "classificacao = {}\n",
    "lista_classificador=[]\n",
    "for frase in tweets_limpos:\n",
    "    palavras_da_frase = list(frase.split())\n",
    "    relevante = 1\n",
    "    irrelevante = 1\n",
    "    \n",
    "    for palavra in palavras_da_frase:\n",
    "\n",
    "        if palavra in relevante_relativa and \\\n",
    "        palavra in irrelevante_relativa:\n",
    "            relevante *= relevante_relativa[palavra]\n",
    "            irrelevante *= irrelevante_relativa[palavra]\n",
    "            \n",
    "        elif palavra in relevante_relativa and \\\n",
    "        palavra not in irrelevante_relativa:\n",
    "            relevante *= relevante_relativa[palavra]\n",
    "            irrelevante *= laplace(palavra,relevante_relativa,irrelevante_relativa)[1]\n",
    "        \n",
    "        elif palavra in irrelevante_relativa and \\\n",
    "        palavra not in relevante_relativa:\n",
    "            relevante *= laplace(palavra,relevante_relativa,irrelevante_relativa)[0]\n",
    "            irrelevante *= irrelevante_relativa[palavra]\n",
    "            \n",
    "        else:\n",
    "            relevante *= laplace(palavra,relevante_relativa,irrelevante_relativa)[0]\n",
    "            irrelevante *= laplace(palavra,relevante_relativa,irrelevante_relativa)[1]\n",
    "            \n",
    "    prob_relevante = probabilidade_relevante*relevante\n",
    "    prob_irrelevante = probabilidade_irrelevante*irrelevante\n",
    "    \n",
    "    if prob_relevante > prob_irrelevante:\n",
    "        classificacao[frase] = 0\n",
    "        lista_classificador.append(0)\n",
    "    else:\n",
    "        classificacao[frase] = 1\n",
    "        lista_classificador.append(1)\n",
    "       \n",
    "classificados = pd.Series(classificacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#comparando o teste com a classificação \n",
    "for tweet in classificacao:\n",
    "    dic={\n",
    "        'Tweet': tweets_limpos,\n",
    "        'Resultafo Teste': lista_classificador,\n",
    "        'Classificação': base_teste[\"Classe\"]\n",
    "    }\n",
    "tabela_classifiação= pd.DataFrame(dic, columns=['Tweet','Resultafo Teste','Classificação'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de acertos= 62.87625418060201%\n",
      "Porcentagem de erros= 37.45819397993311%\n"
     ]
    }
   ],
   "source": [
    "certos=0\n",
    "errados=0\n",
    "\n",
    "for teste,certo in zip(lista_classificador,base_teste[\"Classe\"]):\n",
    "    if teste==certo:\n",
    "        certos+=1\n",
    "    else:\n",
    "        errados+=1\n",
    "       \n",
    "porcentagem_certos=(certos/299)*100\n",
    "porcentagem_errados=(errados/299)*100\n",
    "print(\"Porcentagem de acertos= {}%\".format(porcentagem_certos))\n",
    "print(\"Porcentagem de erros= {}%\".format(porcentagem_errados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de verdadeiros positivos: 56.76855895196506%\n",
      "Porcentagem de falsos positivos: 41.04803493449782%\n",
      "Porcentagem de verdadeiros negativos: 25.327510917030565%\n",
      "Porcentagem de falsos negativos: 0.43668122270742354%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_positivo=0\n",
    "falsos_positivos=0\n",
    "verdadeiros_negativos=0\n",
    "falsos_negativos=0\n",
    "#relevante=0 e irrelevante=1\n",
    "for resultado_teste,resultado_certo in zip(lista_classificador,base_teste[\"Classe\"]):\n",
    "    if resultado_certo==0 and resultado_teste==0:\n",
    "        verdadeiros_positivo+=1\n",
    "    elif resultado_certo==1 and resultado_teste==0:\n",
    "        falsos_positivos+=1\n",
    "    elif resultado_certo==1 and resultado_teste==1:\n",
    "        verdadeiros_negativos+=1\n",
    "    elif falsos_negativos==0 and resultado_teste==1:\n",
    "        falsos_negativos+=1\n",
    "    \n",
    "Porcentagem_verdadeiros_positivo=(verdadeiros_positivo/229)*100\n",
    "Porcentagem_falsos_positivos=(falsos_positivos/229)*100\n",
    "Porcentagem_verdadeiros_negativos=(verdadeiros_negativos/229)*100\n",
    "Porcentagem_falsos_negativos=(falsos_negativos/229)*100\n",
    "\n",
    "print(\"Porcentagem de verdadeiros positivos: {}%\".format(Porcentagem_verdadeiros_positivo))\n",
    "print(\"Porcentagem de falsos positivos: {}%\".format(Porcentagem_falsos_positivos))\n",
    "print(\"Porcentagem de verdadeiros negativos: {}%\".format(Porcentagem_verdadeiros_negativos))\n",
    "print(\"Porcentagem de falsos negativos: {}%\".format(Porcentagem_falsos_negativos))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-dca71a7b300f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;34m'Porcentagem de falsos negativos(%)'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpor_F_N_sem_laplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPorcentagem_falsos_negativos_sem_separar_emoji\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m }\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mtabela_SEMxCOM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Métodos'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Porcentagem de acertos(%)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Porcentagem de verdadeiros positivos(%)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Porcentagem de falsos positivos(%)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Porcentagem de verdadeiros negativos(%)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Porcentagem de falsos negativos(%)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mP_acertos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtabela_SEMxCOM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Porcentagem de acertos(%)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    390\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[0;32m    391\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[1;31m# GH10856\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;31m# raise ValueError if only scalars in dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'arrays must all be same length'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "por_acerts_sem_laplace=62.87625418060201\n",
    "por_V_P_sem_laplace= 56.76855895196506\n",
    "por_F_P_sem_laplace= 41.04803493449782\n",
    "por_V_N_sem_laplace= 25.327510917030565\n",
    "por_F_N_sem_laplace= 0.43668122270742354\n",
    "\n",
    "porcentagem_certos_sem_separar_emoji= 61.87290969899666\n",
    "Porcentagem_verdadeiros_positivo_sem_separar_emoji= 55.895196506550214\n",
    "Porcentagem_falsos_positivos_sem_separar_emoji= 41.48471615720524\n",
    "Porcentagem_verdadeiros_negativos_sem_separar_emoji= 24.890829694323145\n",
    "Porcentagem_falsos_negativos_sem_separar_emoji= 0.43668122270742354\n",
    "\n",
    "data = {\n",
    "'Métodos': ['Sem Laplace', 'Com Laplace', 'Laplace + separação de emoji'],\n",
    "'Porcentagem de acertos(%)': [por_acerts_sem_laplace,porcentagem_certos_sem_separar_emoji],\n",
    "'Porcentagem de verdadeiros positivos(%)':[por_V_P_sem_laplace,Porcentagem_verdadeiros_positivo_sem_separar_emoji],\n",
    "'Porcentagem de falsos positivos(%)':[por_F_P_sem_laplace,Porcentagem_falsos_positivos_sem_separar_emoji],\n",
    "'Porcentagem de verdadeiros negativos(%)':[por_V_N_sem_laplace,Porcentagem_verdadeiros_negativos_sem_separar_emoji],\n",
    "'Porcentagem de falsos negativos(%)':[por_F_N_sem_laplace,Porcentagem_falsos_negativos_sem_separar_emoji]\n",
    "}\n",
    "tabela_SEMxCOM = pd.DataFrame(data, columns=['Métodos', 'Porcentagem de acertos(%)','Porcentagem de verdadeiros positivos(%)','Porcentagem de falsos positivos(%)','Porcentagem de verdadeiros negativos(%)','Porcentagem de falsos negativos(%)'])\n",
    "\n",
    "P_acertos=tabela_SEMxCOM['Porcentagem de acertos(%)']\n",
    "P_V_P=tabela_SEMxCOM['Porcentagem de verdadeiros positivos(%)']\n",
    "P_F_P=tabela_SEMxCOM['Porcentagem de falsos positivos(%)']\n",
    "P_V_N=tabela_SEMxCOM['Porcentagem de verdadeiros negativos(%)']\n",
    "P_F_N=tabela_SEMxCOM['Porcentagem de falsos negativos(%)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'P_acertos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-fb2bea027345>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mP_acertos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bar'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Porcentagem de acertos(%)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'g'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Porcentagem de acertos(%)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SEM X COM'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'P_acertos' is not defined"
     ]
    }
   ],
   "source": [
    "plot = P_acertos.plot(kind='bar',title='Porcentagem de acertos(%)',figsize=(6, 6),color=('b','g'))\n",
    "plt.ylabel('Porcentagem de acertos(%)')\n",
    "plt.xlabel('SEM X COM')\n",
    "plt.show()\n",
    "\n",
    "plot = P_V_P.plot(kind='bar',title='Porcentagem de verdadeiros positivos(%)',figsize=(6, 6),color=('b','g'))\n",
    "plt.ylabel('Porcentagem de verdadeiros positivos(%)')\n",
    "plt.xlabel('SEM X COM')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot = P_F_P.plot(kind='bar',title='Porcentagem de falsos positivos(%)',figsize=(6, 6),color=('b','g'))\n",
    "plt.ylabel('Porcentagem de falsos positivos(%)')\n",
    "plt.xlabel('SEM X COM')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot = P_V_N.plot(kind='bar',title='Porcentagem de verdadeiros negativos(%)',figsize=(6, 6),color=('b','g'))\n",
    "plt.ylabel('Porcentagem de verdadeiros negativos(%)')\n",
    "plt.xlabel('SEM X COM')\n",
    "plt.show()\n",
    "\n",
    "plot = P_F_N.plot(kind='bar',title='PPorcentagem de falsos negativos(%)',figsize=(6, 6),color=('b','g'))\n",
    "plt.ylabel('Porcentagem de falsos negativos(%)')\n",
    "plt.xlabel('SEM X COM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
