{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Ellen Beatriz Shen\n",
    "\n",
    "Nome: Gabriela Moreno Boriero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leitura do excel para treinar o código\n",
    "tudo = pd.read_excel(\"base_acai.xlsx\", sheet_name=\"Treinamento\")\n",
    "\n",
    "#Série de todos os dados + sua tabela absoluta\n",
    "serie_tudo = pd.Series(tudo.Treinamento)\n",
    "tabela_tudo_absoluta = serie_tudo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para limpar os sinais básicos.\n",
    "def limpeza(texto):\n",
    "    import string\n",
    "    pontuacao = '[!-.:?;]'\n",
    "    padrao = re.compile(pontuacao)\n",
    "    text_subbed = re.sub(pattern, ' ', texto)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "relevante_acai = limpeza((open(\"relevante.txt\", \"r\", encoding=\"utf8\").read()).lower())\n",
    "irrelevante_acai = limpeza((open(\"irrelevante.txt\", \"r\", encoding=\"utf8\").read()).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante_relativa = (pd.Series(relevante_acai.split())).value_counts(True)\n",
    "relevante_absoluta = (pd.Series(relevante_acai.split())).value_counts(False)\n",
    "\n",
    "irrelevante_relativa = (pd.Series(irrelevante_acai.split())).value_counts(True)\n",
    "irrelevante_absoluta = (pd.Series(irrelevante_acai.split())).value_counts(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidade_relevante = tabela_relevante.sum()/tabela_tudo_absoluta.sum()\n",
    "probabilidade_irrelevante = tabela_irrelevante.sum()/tabela_tudo_absoluta.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace(palavra, tabela1, tabela2):\n",
    "    if palavra in tabela1:\n",
    "        x = tabela1[palavra]\n",
    "    else:\n",
    "        x = 0\n",
    "        \n",
    "    if palavra in tabela2:\n",
    "        y = tabela2[palavra]\n",
    "    else:\n",
    "        y = 0 \n",
    "    \n",
    "    prob_relevante = (x + 1)/ (len(tabela1) + len(set(tabela1+tabela2)))\n",
    "    prob_irrelevante = (y + 1)/ (len(tabela2) + len(set(tabela1+tabela2)))\n",
    "    return [prob_relevante, prob_irrelevante]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_teste = pd.read_excel(\"base_acai.xlsx\",sheet_name=\"Teste\")\n",
    "series_tweets = pd.Series(list(base_teste.Teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_limpos = []\n",
    "for tweet in series_tweets:\n",
    "    tweets_limpos.append(cleanup(tweet.lower()))\n",
    "\n",
    "    \n",
    "classificacao = {}\n",
    "lista_classificador=[]\n",
    "for frase in tweets_limpos:\n",
    "    palavras_da_frase = list(frase.split())\n",
    "    relevante = 1\n",
    "    irrelevante = 1\n",
    "    \n",
    "    for palavra in palavras_da_frase:\n",
    "\n",
    "        if palavra in relevante_relativa and \\\n",
    "        palavra in irrelevante_relativa:\n",
    "            relevante *= relevante_relativa[palavra]\n",
    "            irrelevante *= irrelevante_relativa[palavra]\n",
    "            \n",
    "        elif palavra in relevante_relativa and \\\n",
    "        palavra not in irrelevante_relativa:\n",
    "            relevante *= relevante_relativa[palavra]\n",
    "            irrelevante *= laplace(palavra,relevante_relativa,irrelevante_relativa)[1]\n",
    "        \n",
    "        elif palavra in irrelevante_relativa and \\\n",
    "        palavra not in relevante_relativa:\n",
    "            relevante *= laplace(palavra,relevante_relativa,irrelevante_relativa)[0]\n",
    "            irrelevante *= irrelevante_relativa[palavra]\n",
    "            \n",
    "        else:\n",
    "            relevante *= laplace(palavra,relevante_relativa,irrelevante_relativa)[0]\n",
    "            irrelevante *= laplace(palavra,relevante_relativa,irrelevante_relativa)[1]\n",
    "            \n",
    "    prob_relevante = probabilidade_relevante*relevante\n",
    "    prob_irrelevante = probabilidade_irrelevante*irrelevante\n",
    "    \n",
    "    if prob_relevante > prob_irrelevante:\n",
    "        classificacao[frase] = 0\n",
    "        lista_classificador.append(0)\n",
    "    else:\n",
    "        classificacao[frase] = 1\n",
    "        lista_classificador.append(1)\n",
    "       \n",
    "classificados = pd.Series(classificacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparando o teste com a classificação \n",
    "for tweet in classificacao:\n",
    "    dic={\n",
    "        'Tweet': tweets_limpos,\n",
    "        'Resultafo Teste': lista_classificador,\n",
    "        'Classificação': base_teste[\"Classe\"]\n",
    "    }\n",
    "tabela_classifiação= pd.DataFrame(dic, columns=['Tweet','Resultafo Teste','Classificação'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "certos=0\n",
    "errados=0\n",
    "\n",
    "for teste,certo in zip(lista_classificador,base_teste[\"Classe\"]):\n",
    "    if teste==certo:\n",
    "        certos+=1\n",
    "    else:\n",
    "        errados+=1\n",
    "       \n",
    "porcentagem_certos=(certos/299)*100\n",
    "porcentagem_errados=(errados/299)*100\n",
    "print(\"Porcentagem de acertos= {}%\".format(porcentagem_certos))\n",
    "print(\"Porcentagem de erros= {}%\".format(porcentagem_errados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verdadeiros_positivo=0\n",
    "falsos_positivos=0\n",
    "verdadeiros_negativos=0\n",
    "falsos_negativos=0\n",
    "#relevante=0 e irrelevante=1\n",
    "for resultado_teste,resultado_certo in zip(lista_classificador,base_teste[\"Classe\"]):\n",
    "    if resultado_certo==0 and resultado_teste==0:\n",
    "        verdadeiros_positivo+=1\n",
    "    elif resultado_certo==1 and resultado_teste==0:\n",
    "        falsos_positivos+=1\n",
    "    elif resultado_certo==1 and resultado_teste==1:\n",
    "        verdadeiros_negativos+=1\n",
    "    elif falsos_negativos==0 and resultado_teste==1:\n",
    "        falsos_negativos+=1\n",
    "    \n",
    "Porcentagem_verdadeiros_positivo=(verdadeiros_positivo/229)*100\n",
    "Porcentagem_falsos_positivos=(falsos_positivos/229)*100\n",
    "Porcentagem_verdadeiros_negativos=(verdadeiros_negativos/229)*100\n",
    "Porcentagem_falsos_negativos=(falsos_negativos/229)*100\n",
    "\n",
    "print(\"Porcentagem de verdadeiros positivos: {}%\".format(Porcentagem_verdadeiros_positivo))\n",
    "print(\"Porcentagem de falsos positivos: {}%\".format(Porcentagem_falsos_positivos))\n",
    "print(\"Porcentagem de verdadeiros negativos: {}%\".format(Porcentagem_verdadeiros_negativos))\n",
    "print(\"Porcentagem de falsos negativos: {}%\".format(Porcentagem_falsos_negativos))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
